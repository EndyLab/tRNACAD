{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44d6246-dbf0-4f1e-affb-7edb663f9993",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df18260b-fbdc-4ddb-9aef-ec3446567cad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Iterable, Callable\n",
    "from itertools import takewhile\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import ks_2samp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b1dfb-e450-4493-838e-173dfdfb1385",
   "metadata": {},
   "source": [
    "## Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c57acbc-7958-4f90-92b1-ac9c2065fc4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "def smoothing(df: pd.DataFrame, key: str, kernel_width: float) -> np.ndarray:\n",
    "    return gaussian_filter1d(df[key], sigma=kernel_width)\n",
    "\n",
    "\n",
    "# FUNCTION NOT USED! KEPT HERE FOR REFERENCE IMPLEMENTATION\n",
    "#\n",
    "# def derivative(df: pd.DataFrame, key: str = \"smoothed_fluorescence\") -> np.ndarray:\n",
    "#     # calculate timestep\n",
    "#     time = df.time.map(lambda t: pd.to_datetime(t))\n",
    "#     dt = int(np.diff(time).mean()) / 1e9  # in seconds\n",
    "#\n",
    "#     # calculate derivative\n",
    "#     grad = np.gradient(df[key]) / dt\n",
    "#     return grad\n",
    "\n",
    "\n",
    "def rolling_average(arr: Iterable, width: int = 5) -> np.ndarray:\n",
    "    window = np.ones(width) / width\n",
    "    return np.convolve(arr, window, mode=\"same\")\n",
    "\n",
    "\n",
    "def load_namemap(platemap_filepath: str) -> dict:\n",
    "    # load map of conditions to plate locations (.csv)\n",
    "    platemap = (\n",
    "        pd.read_csv(platemap_filepath)\n",
    "        .dropna()\n",
    "        .set_index(\"Rows/Cols\")\n",
    "        .T\n",
    "        .unstack()\n",
    "    )\n",
    "    platemap = platemap[platemap != '-']\n",
    "\n",
    "    # extract location names from platemap index\n",
    "    locs = [\n",
    "        \"\".join(loc_tup)\n",
    "        for loc_tup in platemap.index\n",
    "    ]\n",
    "    # extract conditions from platemap values\n",
    "    conditions = platemap.values\n",
    "\n",
    "    # make dict mapping locations to conditions\n",
    "    namemap = dict(zip(locs, conditions))\n",
    "\n",
    "    return namemap\n",
    "\n",
    "\n",
    "def load_experiment(\n",
    "        data_filepath: str, namemap: dict, date: str,\n",
    "        smoothing_parameter: float,\n",
    "        rolling_average_window_length: int,\n",
    ") -> pd.DataFrame:\n",
    "    # load dataframe and massage\n",
    "    df = (\n",
    "        pd.read_csv(data_filepath)\n",
    "        .drop([\"Unnamed: 0\", \"Temperature(Â¡C)\"], axis=1)\n",
    "        .set_index(\"Time\")\n",
    "    )\n",
    "\n",
    "    # generate dataframe for each replicate\n",
    "    dict_of_dfs_raw = {\n",
    "        loc: pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"loc\": loc,\n",
    "                \"time\": df[loc].index,\n",
    "                \"fluorescence\": df[loc].values,\n",
    "                \"condition\": cond\n",
    "            }\n",
    "        )\n",
    "        for loc, cond in namemap.items()\n",
    "    }\n",
    "    # calculate smoothed fluorescence trace for each replicate\n",
    "    for _, df in dict_of_dfs_raw.items():\n",
    "        df[\"smoothed_fluorescence\"] = smoothing(df, key=\"fluorescence\", kernel_width=smoothing_parameter)\n",
    "\n",
    "    # calculate background fluorescence to subtract from traces\n",
    "    negs = pd.concat([\n",
    "        dict_of_dfs_raw[loc]\n",
    "        for loc, cond in namemap.items()\n",
    "        if cond == \"(-)\"\n",
    "    ])\n",
    "    background = negs.groupby(\"time\")[\"smoothed_fluorescence\"].mean()\n",
    "\n",
    "    # iterate over unnormalized dict of dfs\n",
    "    dict_of_dfs_processed = {}\n",
    "    for loc, df in dict_of_dfs_raw.items():\n",
    "        # background subtraction\n",
    "        backgroud_corrected_fluorescence = df[\"fluorescence\"] - background.values\n",
    "        smoothed_fluorescence = df[\"smoothed_fluorescence\"] - background.values\n",
    "\n",
    "        # calculate timestep\n",
    "        time = df.time.map(lambda t: pd.to_datetime(t))\n",
    "        dt = int(np.diff(time).mean()) / 1e9  # in seconds\n",
    "\n",
    "        # calculate derivative\n",
    "        grad = np.gradient(smoothed_fluorescence) / dt\n",
    "\n",
    "        # calculate rolling average of derivative\n",
    "        rolling_average_derivative = rolling_average(grad, rolling_average_window_length)\n",
    "\n",
    "        dict_of_dfs_processed[loc] = pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"date\": date,\n",
    "                \"loc\": loc,\n",
    "                \"condition\": df[\"condition\"],\n",
    "                \"time\": df[\"time\"],\n",
    "                \"raw_fluorescence\": df[\"fluorescence\"],\n",
    "                \"bkgrd_sub_fluorescence\": backgroud_corrected_fluorescence,\n",
    "                \"smoothed_fluorescence\": smoothed_fluorescence,\n",
    "                \"derivative\": grad,\n",
    "                \"smoothed_derivative\": gaussian_filter1d(grad, smoothing_parameter),\n",
    "                \"rolling_derivative\": rolling_average_derivative,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # turn dictionary of processed dataframes into one big dataframe\n",
    "    df = pd.concat(dict_of_dfs_processed.values()).reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(\n",
    "        # date -> (platemap_filepath, data_filepath)\n",
    "        experiment_filepaths: dict[str, tuple[str, str]],\n",
    "        smoothing_parameter: float = 0.5,\n",
    "        rolling_average_window_length: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    # load dataframes for each day of experiments\n",
    "    list_of_dfs = [\n",
    "        load_experiment(\n",
    "            data_filepath=data_filepath, namemap=load_namemap(platemap_filepath), date=date,\n",
    "            smoothing_parameter=smoothing_parameter,\n",
    "            rolling_average_window_length=rolling_average_window_length\n",
    "        )\n",
    "        for date, (platemap_filepath, data_filepath) in experiment_filepaths.items()\n",
    "    ]\n",
    "    # concatenate list of dataframes into one big dataframe and return\n",
    "    data = pd.concat(list_of_dfs).reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_outliers_timeseries(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # get dataframe with single row per experimental replicate\n",
    "    vmax_df = df[df[\"index\"] == 42]\n",
    "\n",
    "    # MANUALLY IDENTIFIED OUTLIERS!\n",
    "    #\n",
    "    # NOTE: we did not remove outliers in the\n",
    "    #  final analysis presented in the manuscript;\n",
    "    #  this code was used for dev only\n",
    "    outlier_ix = {\n",
    "        # 220728\n",
    "        42,  # GAfast\n",
    "        235, 2937,  # GAslow\n",
    "    }\n",
    "    # get pd.Series for each row identified by outlier_ix\n",
    "    outlier_series = [vmax_df.loc[ix] for ix in outlier_ix]\n",
    "\n",
    "    # create list of dicts of comparables (key -> Any)\n",
    "    # and each\n",
    "    outlier_identifiers = [\n",
    "        {key: series[key] for key in \"date loc\".split()}  # each item represents the val of the outlier\n",
    "        for series in outlier_series  # each dict represents a single outlier\n",
    "    ]\n",
    "\n",
    "    # generate masks to identify outliers by comparing df to those key, value pairs\n",
    "    each_outlier_mask = []\n",
    "    for outlier_dict in outlier_identifiers:\n",
    "        # generate mask to find indices that match each individual key val pair\n",
    "        #   for a given outlier\n",
    "        each_outlier_keyval_mask = [\n",
    "            df[key] == val\n",
    "            for key, val in outlier_dict.items()\n",
    "        ]\n",
    "\n",
    "        # generate mask for each outlier, which is where all keyval pair\n",
    "        each_outlier_mask.append(np.logical_and.reduce(each_outlier_keyval_mask))\n",
    "\n",
    "    # generate masks for all outliers, which is where any mask is TRUE\n",
    "    combined_mask = np.logical_or.reduce(each_outlier_mask)\n",
    "\n",
    "    # return NOT outliers\n",
    "    return df[~combined_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30122790-8082-49c2-8d42-0c2b6b3c7e99",
   "metadata": {},
   "source": [
    "## Getter Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68aa4b42-9dbf-4bbf-aeb2-0762f44b8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTER FUNCTIONS\n",
    "def make_getter_function(conditions: Iterable[str]) -> Callable[[pd.DataFrame], pd.DataFrame]:\n",
    "    def get_conditions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        filtered = df[df[\"condition\"].map(lambda cond: cond in conditions)]\n",
    "        return filtered\n",
    "    return get_conditions\n",
    "\n",
    "\n",
    "get_experimental_conditions = make_getter_function({\"GAfast\", \"GAslow\", \"(-)\", \"uniform\", \"Uniform\"})\n",
    "get_traces_conditions = make_getter_function({\"GAfast\", \"GAslow\", \"(-)\", \"uniform\"})\n",
    "get_barplot_conditions = make_getter_function({\"GAfast\", \"GAslow\", \"uniform\"})\n",
    "get_syn_tRNAs = make_getter_function({\"GAfast\", \"GAslow\", \"uniform\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1c919-e970-42c2-a67a-fae189bf160c",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3577f864-601e-4423-8022-a19be777bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING PARAMETERS\n",
    "hue_order = \"uniform GAslow GAfast (-)\".split()\n",
    "cmap = dict(zip(hue_order, sns.color_palette()))\n",
    "cmap[\"Uniform\"] = cmap[\"uniform\"]\n",
    "cmap[\"(-)\"] = (0, 0, 0)\n",
    "cmap[\"(+)\"] = (0, 0, 0)\n",
    "\n",
    "\n",
    "def set_xaxis_time(ax, tight: bool = False, last_timepoint: str = \"12hrs\") -> Axes:\n",
    "    tick_names = [\"0hrs\", \"4hrs\", \"8hrs\", \"12hrs\", \"16hrs\"]\n",
    "    n = len(tick_names)\n",
    "    tick_locs = [int(i / (n - 1) * len(ax.get_xticks())) for i in range(n)]\n",
    "    tick_dict = dict(zip(tick_names, tick_locs))\n",
    "\n",
    "    if last_timepoint is not None:\n",
    "        # truncate plot\n",
    "        ax.set_xlim(0, tick_dict[last_timepoint])\n",
    "        # truncate tick_names and tick_locs\n",
    "        tick_names, tick_locs = list(zip(*takewhile(lambda tup: tup[1] <= tick_dict[last_timepoint], tick_dict.items())))\n",
    "\n",
    "    if tight:\n",
    "        # only take first and last values of tick_names and tick_locs\n",
    "        tick_names = [tick_names[0], tick_names[-1]]\n",
    "        tick_locs = [tick_locs[0], tick_locs[-1]]\n",
    "\n",
    "    ax.set_xticks(tick_locs, tick_names)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_line_seaborn(\n",
    "        df: pd.DataFrame,\n",
    "        xkey=\"time\", ykey=\"bkgrd_sub_fluorescence\",\n",
    "        traces=False,\n",
    "        ax=None,\n",
    "        legend: bool = True,\n",
    "        format_xaxis: bool = True, time_tight: bool = False,\n",
    "        outpath: str = None,\n",
    ") -> Axes:\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    estimator = \"mean\" if traces is False else None\n",
    "    sns.lineplot(\n",
    "        data=df, x=xkey, y=ykey,\n",
    "        hue=\"condition\", alpha=0.5,\n",
    "        palette=cmap, legend=legend,\n",
    "        estimator=estimator,\n",
    "        ax=ax\n",
    "    )\n",
    "    if ykey == \"derivative\":\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "    if format_xaxis:\n",
    "        ax = set_xaxis_time(ax, time_tight)\n",
    "\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_trace(\n",
    "        # data analysis parameters\n",
    "        plotted: pd.DataFrame,\n",
    "        threshkey: str = None,\n",
    "        left_threshold: float = None, right_threshold: float = None,\n",
    "        # specify variables to plot\n",
    "        xkey: str = \"time\",\n",
    "        ykey: str = \"bkgrd_sub_fluorescence\", ystyle: str = \"-\",\n",
    "        y2key: str = None, y2style: str = \":\",\n",
    "        # plotting parameters\n",
    "        ax: Axes = None,\n",
    "        format_xaxis: bool = True,\n",
    "        plot_bounds: bool = True,                                   # plot integration bounds?\n",
    "        ylim: tuple[float, float] = None,\n",
    "        plot_title: str = None,\n",
    "        outpath: str = None\n",
    "):\n",
    "    if ylim is None:\n",
    "        vals = [\n",
    "            val\n",
    "            for key in (ykey, y2key) if key is not None\n",
    "            for val in plotted[key]\n",
    "        ]\n",
    "        ylim = (min(vals), max(vals))\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    cond = set(plotted[\"condition\"]).pop()\n",
    "\n",
    "    x = plotted[xkey]\n",
    "    y1 = plotted[ykey]\n",
    "\n",
    "    # plot data\n",
    "    ax.plot(x, y1, ystyle, color=cmap[cond])\n",
    "\n",
    "    if y2key is not None:\n",
    "        y2 = plotted[y2key]\n",
    "        ax.plot(x, y2, y2style, color=cmap[cond])\n",
    "\n",
    "\n",
    "    if plot_bounds:\n",
    "        # plot horizontal line across y=0\n",
    "        ax.plot(np.zeros_like(y1), '--k')\n",
    "\n",
    "        # get vertical lines for this trace\n",
    "        vert = np.linspace(ylim[0], ylim[1], len(y1))\n",
    "\n",
    "        # get xval arrays for vertical lines at integration bounds\n",
    "        lowix, highix = get_integration_bounds(\n",
    "            plotted, threshkey=threshkey,\n",
    "            left_threshold=left_threshold, right_threshold=right_threshold\n",
    "        )\n",
    "        lowbound = np.ones_like(x) * lowix\n",
    "        highbound = np.ones_like(x) * highix\n",
    "\n",
    "        # plot integration bounds\n",
    "        ax.plot(lowbound, vert, \"--k\")\n",
    "        ax.plot(highbound, vert, \"--k\")\n",
    "\n",
    "    if format_xaxis:\n",
    "        ax = set_xaxis_time(ax)\n",
    "\n",
    "    if plot_title is not None:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_traces(\n",
    "       # data analysis parameters\n",
    "        plotted: pd.DataFrame,\n",
    "        threshkey: str = None,\n",
    "        left_threshold: float = None, right_threshold: float = None,\n",
    "        # specify variables to plot\n",
    "        huekey: str = \"condition\",\n",
    "        xkey: str = \"time\",\n",
    "        ykey: str = \"bkgrd_sub_fluorescence\", ystyle: str = \"-\",\n",
    "        y2key: str = None, y2style: str = \":\",\n",
    "        # plotting parameters\n",
    "        ax: Axes = None,\n",
    "        format_xaxis: bool = True,\n",
    "        plot_bounds: bool = True,                                   # plot integration bounds?\n",
    "        ylim: tuple[float, float] = None,\n",
    "        plot_title: str = None,\n",
    "        outpath: str = None\n",
    "):\n",
    "    if ylim is None:\n",
    "        vals = [\n",
    "            val\n",
    "            for key in (ykey, y2key) if key is not None\n",
    "            for val in plotted[key]\n",
    "        ]\n",
    "        ylim = (min(vals), max(vals))\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    for hueval, df in plotted.groupby(huekey):\n",
    "        ax = plot_trace(\n",
    "            plotted=df, threshkey=threshkey, left_threshold=left_threshold, right_threshold=right_threshold,\n",
    "            xkey=xkey, ykey=ykey, ystyle=ystyle, y2key=y2key, y2style=y2style,\n",
    "            ax=ax, format_xaxis=False, plot_bounds=plot_bounds, ylim=ylim\n",
    "        )\n",
    "    if plot_title is not None:\n",
    "        ax.set_title(plot_title)\n",
    "\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_traces_grid(\n",
    "        # data analysis parameters\n",
    "        plotted: pd.DataFrame,\n",
    "        threshkey: str = None, left_threshold: float = None, right_threshold: float = None,\n",
    "        # specify plot layout\n",
    "        rowkey: str = \"condition\", colkey: str = \"loc\",\n",
    "        # specify variables to plot\n",
    "        xkey: str = \"time\", ykey: str = \"bkgrd_sub_fluorescence\",\n",
    "        y2key: str = None,\n",
    "        # plotting parameters\n",
    "        figsize: tuple[float, float] = (10, 5),\n",
    "        plot_bounds: bool = True,                                   # plot integration bounds?\n",
    "        plot_title: str = None,\n",
    "        ylim: tuple[float, float] = None,\n",
    "        tight_xaxis_labels: bool = True,\n",
    "        outpath: str = None\n",
    "):\n",
    "    # flag if plot_bounds need to be calculated for each row\n",
    "    calc_ylim = (ylim is None)\n",
    "\n",
    "    # group data by rowkey\n",
    "    list_df_by_rowkey = list(plotted.groupby(rowkey))\n",
    "\n",
    "    # get number of valid columns per condition\n",
    "    ncols_per_row = {\n",
    "        row: len(set(df[colkey]))\n",
    "        for row, df in list_df_by_rowkey\n",
    "    }\n",
    "\n",
    "    # get dimensions of subplots\n",
    "    nrows = len(list_df_by_rowkey)\n",
    "    ncols = max(ncols_per_row.values())\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    fig.tight_layout(h_pad=2)\n",
    "\n",
    "    # iterate through conditions and plot\n",
    "    for (row, df_by_row), ax_rows in zip(list_df_by_rowkey, axes):\n",
    "\n",
    "        # get plot bounds if not specified\n",
    "        if calc_ylim:\n",
    "            vals = [\n",
    "                val\n",
    "                for key in (ykey, y2key) if key is not None\n",
    "                for val in df_by_row[key]\n",
    "            ]\n",
    "            ylim = (min(vals), max(vals))\n",
    "\n",
    "        if ncols == 1:\n",
    "            ax_rows = [ax_rows]  # ax rows should be a list, but rn is just an Axes object\n",
    "\n",
    "        for (col, df), ax in zip(df_by_row.groupby(colkey), ax_rows):\n",
    "            for (_, plotted) in df.groupby(\"loc\"):\n",
    "                ax = plot_trace(\n",
    "                    plotted=plotted,\n",
    "                    threshkey=threshkey, left_threshold=left_threshold, right_threshold=right_threshold,\n",
    "                    xkey=xkey, ykey=ykey, y2key=y2key,\n",
    "                    ax=ax, plot_bounds=plot_bounds, ylim=ylim,\n",
    "                    format_xaxis=False\n",
    "                )\n",
    "\n",
    "                # format\n",
    "                ax.set_title(f\"{row} {col}\")\n",
    "\n",
    "                ax.set_ylim(ylim)\n",
    "\n",
    "            set_xaxis_time(ax, tight=tight_xaxis_labels)\n",
    "\n",
    "    if plot_title is not None:\n",
    "        plt.suptitle(plot_title)\n",
    "        plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath)\n",
    "\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edab3c-87a2-477f-ac08-03d4deb96afb",
   "metadata": {},
   "source": [
    "## Calculate Translation Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf26c595-c3d1-4123-a15a-aa17bbc4f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integration_bounds(\n",
    "        df: pd.DataFrame, threshkey: str,\n",
    "        left_threshold: float, right_threshold: float,\n",
    ") -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    dataframe MAY be grouped by date and condition already\n",
    "    (will work on single trace dataframes)\n",
    "    \"\"\"\n",
    "    mean_trace = df.groupby(\"time\")[threshkey].mean()[:12 * 12]\n",
    "\n",
    "    lowix = int(np.argmax(mean_trace >= left_threshold * max(mean_trace)))\n",
    "\n",
    "    reverse_indices = np.arange(len(mean_trace))[::-1]\n",
    "    highix = int(reverse_indices[np.argmax(mean_trace[::-1] >= right_threshold * max(mean_trace))])\n",
    "\n",
    "    return lowix, highix\n",
    "\n",
    "\n",
    "def get_average_rate(\n",
    "        df: pd.DataFrame,\n",
    "        bound_ix: tuple[float, float],\n",
    "        integratekey: str,\n",
    "        vmax=False\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    12 ~ 1 hr\n",
    "    36 ~ 3 hrs\n",
    "    48 ~ 4 hrs\n",
    "    \"\"\"\n",
    "    if vmax is True:\n",
    "        return max(df[integratekey])\n",
    "    else:\n",
    "        ix0, ix1 = bound_ix\n",
    "        time = df.time.map(lambda t: pd.to_datetime(t))\n",
    "        dt = int(np.diff(time).mean()) / 1e9  # in seconds\n",
    "        time_window = (ix1 - ix0 + 1) * dt\n",
    "        integral = df.iloc[ix0:ix1 + 1][integratekey].sum()\n",
    "        integral /= time_window\n",
    "        return integral\n",
    "\n",
    "\n",
    "def norm_by_GAfast(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    def normalize(df: pd.DataFrame):\n",
    "        GA_fast_mean = df[df.condition == \"GAfast\"][\"average_rate\"].mean()\n",
    "        df[\"normalized_rate\"] = df[\"average_rate\"] / GA_fast_mean\n",
    "\n",
    "        return df\n",
    "\n",
    "    data = data.groupby(\"date\").apply(normalize)\n",
    "    data[\"elong_norm\"] = 1 / data[\"normalized_rate\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_avg_rate_df(\n",
    "        df: pd.DataFrame, leftthresh: float, rightthresh: float,\n",
    "        threshkey: str = \"derivative\", integratekey: str = \"derivative\", vmax=False\n",
    ") -> pd.DataFrame:\n",
    "    avg_rate_dicts = [\n",
    "        {\n",
    "            \"date\": date,\n",
    "            \"loc\": loc,\n",
    "            \"condition\": cond,\n",
    "            \"average_rate\": get_average_rate(\n",
    "                df=df,\n",
    "                bound_ix=get_integration_bounds(\n",
    "                    df=df, threshkey=threshkey,\n",
    "                    left_threshold=leftthresh, right_threshold=rightthresh\n",
    "                ),\n",
    "                integratekey=integratekey,\n",
    "                vmax=vmax\n",
    "            )\n",
    "        }\n",
    "        for (date, cond), df_by_cond in df.groupby([\"date\", \"condition\"])\n",
    "        for loc, df in df_by_cond.groupby(\"loc\")\n",
    "    ]\n",
    "    avg_rate_series = [\n",
    "        pd.Series(data=d, index=d.keys())\n",
    "        for d in avg_rate_dicts\n",
    "    ]\n",
    "    avg_rate_df = pd.concat(avg_rate_series, axis=1).T\n",
    "    return avg_rate_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08b2e2-f052-4900-9d45-2585e1c11fb3",
   "metadata": {},
   "source": [
    "# Paper Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccf4c8-ca4f-4078-9d14-02776cd6185f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a1acaf-4672-4cee-9c30-97124b62ff53",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '220728_platemap.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m barplotval \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m vmax_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m data_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_filepaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothing_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m no_outliers \u001b[38;5;241m=\u001b[39m remove_outliers_timeseries(data_df)\n\u001b[1;32m     19\u001b[0m rate_df \u001b[38;5;241m=\u001b[39m norm_by_GAfast(\n\u001b[1;32m     20\u001b[0m     get_avg_rate_df(\n\u001b[1;32m     21\u001b[0m         get_barplot_conditions(no_outliers),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 129\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(experiment_filepaths, smoothing_parameter, rolling_average_window_length)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;66;03m# date -> (platemap_filepath, data_filepath)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m         experiment_filepaths: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# load dataframes for each day of experiments\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     list_of_dfs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamemap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_namemap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatemap_filepath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m            \u001b[49m\u001b[43msmoothing_parameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmoothing_parameter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrolling_average_window_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrolling_average_window_length\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatemap_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_filepath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_filepaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# concatenate list of dataframes into one big dataframe and return\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(list_of_dfs)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;66;03m# date -> (platemap_filepath, data_filepath)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m         experiment_filepaths: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# load dataframes for each day of experiments\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     list_of_dfs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    130\u001b[0m         load_experiment(\n\u001b[0;32m--> 131\u001b[0m             data_filepath\u001b[38;5;241m=\u001b[39mdata_filepath, namemap\u001b[38;5;241m=\u001b[39m\u001b[43mload_namemap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatemap_filepath\u001b[49m\u001b[43m)\u001b[49m, date\u001b[38;5;241m=\u001b[39mdate,\n\u001b[1;32m    132\u001b[0m             smoothing_parameter\u001b[38;5;241m=\u001b[39msmoothing_parameter,\n\u001b[1;32m    133\u001b[0m             rolling_average_window_length\u001b[38;5;241m=\u001b[39mrolling_average_window_length\n\u001b[1;32m    134\u001b[0m         )\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m date, (platemap_filepath, data_filepath) \u001b[38;5;129;01min\u001b[39;00m experiment_filepaths\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    136\u001b[0m     ]\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# concatenate list of dataframes into one big dataframe and return\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(list_of_dfs)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m, in \u001b[0;36mload_namemap\u001b[0;34m(platemap_filepath)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_namemap\u001b[39m(platemap_filepath: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# load map of conditions to plate locations (.csv)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     platemap \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 26\u001b[0m         \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplatemap_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRows/Cols\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;241m.\u001b[39munstack()\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     platemap \u001b[38;5;241m=\u001b[39m platemap[platemap \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# extract location names from platemap index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '220728_platemap.csv'"
     ]
    }
   ],
   "source": [
    "experiments = {\n",
    "    # date -> (platemap_filepath, data_filepath)\n",
    "    \"220728\": (\n",
    "        \"experimental_data/220728_platemap.csv\", \n",
    "        \"experimental_data/220728_fluorescence_data.csv\"\n",
    "    ),\n",
    "    \"220801\": (\n",
    "        \"experimental_data/220801_platemap.csv\", \n",
    "        \"experimental_data/220801_fluorescence_data.csv\"\n",
    "    ),\n",
    "    \"221207\": (\n",
    "        \"experimental_data/221207_platemap.csv\", \n",
    "        \"experimental_data/221207_fluorescence_data.csv\"\n",
    "    )\n",
    "}\n",
    "\n",
    "sigma=10\n",
    "left_thresh = 0.50\n",
    "right_thresh = 0.50\n",
    "thresh_key = \"smoothed_derivative\"\n",
    "integrate_key = \"smoothed_derivative\"\n",
    "barplotval = \"normalized_rate\"\n",
    "vmax_flag = False\n",
    "\n",
    "\n",
    "data_df = load_data(experiment_filepaths=experiments, smoothing_parameter=sigma)\n",
    "no_outliers = remove_outliers_timeseries(data_df)\n",
    "rate_df = norm_by_GAfast(\n",
    "    get_avg_rate_df(\n",
    "        get_barplot_conditions(no_outliers),\n",
    "        threshkey=thresh_key, integratekey=integrate_key,\n",
    "        leftthresh=left_thresh, rightthresh=right_thresh,\n",
    "        vmax=vmax_flag\n",
    "    )\n",
    ")\n",
    "rate_w_outliers = norm_by_GAfast(\n",
    "    get_avg_rate_df(\n",
    "        get_barplot_conditions(data_df),\n",
    "        threshkey=thresh_key, integratekey=integrate_key,\n",
    "        leftthresh=left_thresh, rightthresh=right_thresh,\n",
    "        vmax=vmax_flag\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3db634-aa40-4963-9007-68c9039e05e4",
   "metadata": {},
   "source": [
    "## Plot translation rate bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5be3a3-5fb0-4151-9fed-8b35952f43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted = get_barplot_conditions(rate_w_outliers)\n",
    "\n",
    "ax = sns.stripplot(\n",
    "    data=plotted, x=barplotval, y=\"condition\",\n",
    "    palette=cmap, size=10, linewidth=2\n",
    ")\n",
    "ax = sns.barplot(\n",
    "    data=plotted, x=barplotval, y=\"condition\",\n",
    "    hue_order=hue_order, palette=cmap, orient=\"h\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# plt.savefig(f\"../figures/rates_bar_plot.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8882ba6-f1de-4bff-8539-3c53b1b70b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = plotted\n",
    "df[\"normalized_rate\"] = df[\"normalized_rate\"].astype(\"float\")\n",
    "df.groupby([\"date\", \"condition\"])[\"normalized_rate\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf1d25-cd8b-4d8b-8e2e-d3ff3ad1fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted[\"normalized_rate\"] = plotted[\"normalized_rate\"].astype(float)\n",
    "plotted.groupby(\"condition\")[\"normalized_rate\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7a57b-4c2f-4deb-93c0-84fbd58d81ba",
   "metadata": {},
   "source": [
    "## 220801 representative fluorescence vs time traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ca6a5-4b4e-46cd-9ff7-8ef1253d48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_traces_conditions(data_df)\n",
    "plotted = df[df[\"date\"] == \"220801\"]\n",
    "means = plotted.groupby([\"condition\", \"time\"])[\"smoothed_fluorescence\"].mean().reset_index()\n",
    "ax = plot_line_seaborn(plotted, ykey=\"bkgrd_sub_fluorescence\", format_xaxis=False, legend=True)\n",
    "ax = plot_traces(\n",
    "    plotted=means,\n",
    "    ykey=\"smoothed_fluorescence\", ystyle=\":\",\n",
    "    ax=ax, format_xaxis=False,\n",
    "    plot_bounds=False\n",
    ")\n",
    "set_xaxis_time(ax, last_timepoint=\"12hrs\")\n",
    "ax.set_ylim([-5000, 30000])\n",
    "# plt.savefig(\"../figures/220801_raw_traces.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e91011-90b7-4f40-b528-7f52990200d2",
   "metadata": {},
   "source": [
    "## Mean Derivative vs Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f35fb6-ff33-47fe-a340-e3044fddbdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_traces_conditions(data_df)\n",
    "plotted = df[df[\"date\"]==\"220801\"]\n",
    "plot_line_seaborn(\n",
    "    df=plotted, ykey=\"smoothed_derivative\", \n",
    "    # outpath=\"../figures/220801_mean_derivative_vs_condition.svg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2838c858-70b7-4f40-857c-d5fb42f9c67e",
   "metadata": {},
   "source": [
    "## fluorescence vs day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb56102-59ec-44a7-91d1-5b35aba1b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted = get_barplot_conditions(no_outliers)\n",
    "# plotted = get_barplot_conditions(data_df)\n",
    "plot_traces_grid(\n",
    "    plotted=plotted, \n",
    "    threshkey=thresh_key, left_threshold=left_thresh, right_threshold=right_thresh,\n",
    "    rowkey=\"date\", colkey=\"condition\",\n",
    "    ykey=\"smoothed_fluorescence\", \n",
    "    y2key=\"bkgrd_sub_fluorescence\",\n",
    "    plot_bounds=False,\n",
    "    tight_xaxis_labels=False,\n",
    "    figsize=(10,8), \n",
    "    # outpath=\"../graph_gazing/derivatives_vs_loc.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97967039-8092-47a5-8448-9c5c069cdfd0",
   "metadata": {},
   "source": [
    "## derivatives vs day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9019354-1616-4b7b-81ce-62f7ce59e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted = get_barplot_conditions(no_outliers)\n",
    "# plotted = get_barplot_conditions(data_df)\n",
    "plot_traces_grid(\n",
    "    plotted=plotted, \n",
    "    threshkey=thresh_key, left_threshold=left_thresh, right_threshold=right_thresh,\n",
    "    rowkey=\"date\", colkey=\"condition\",\n",
    "    ykey=\"derivative\", \n",
    "    # y2key=\"bkgrd_sub_fluorescence\",\n",
    "    plot_bounds=True,\n",
    "    tight_xaxis_labels=False,\n",
    "    figsize=(10,8), \n",
    "    # outpath=\"../graph_gazing/derivatives_vs_loc.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7883240a-9ee0-4839-9ac1-ad05d1993a90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 221207 derivatives vs well location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857485b-8489-4424-a54f-7d46149e362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = no_outliers\n",
    "# df = data_df\n",
    "plotted = get_barplot_conditions(df[df[\"date\"] == \"221207\"])\n",
    "plot_traces_grid(\n",
    "    plotted=plotted, \n",
    "    threshkey=thresh_key, left_threshold=left_thresh, right_threshold=right_thresh,\n",
    "    rowkey=\"condition\", colkey=\"loc\",\n",
    "    ykey=\"derivative\", \n",
    "    # y2key=\"derivative\",\n",
    "    plot_bounds=False,\n",
    "    tight_xaxis_labels=False,\n",
    "    # figsize=(10,8), outpath=\"../graph_gazing/221207_derivative_vs_loc.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb5202-cda3-4459-947f-9441f93682a9",
   "metadata": {},
   "source": [
    "## Integration Parameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354b050-8d00-435a-ba18-f1635f7324e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_bounds(thresh: str):\n",
    "    bounds_set = {\n",
    "        \"low_ten_percent\": (0.1, 0.1),\n",
    "        \"low_quartile\": (0.25, 0.25),\n",
    "        \"halfmax\": (0.5, 0.5),\n",
    "        \"high_quartile\": (0.75, 0.75),\n",
    "        \"high_ten_percent\": (0.9, 0.9),\n",
    "        \"low_high\": (0.1, 0.9),\n",
    "        \"zero_bounds\": (0,0)\n",
    "    }\n",
    "    rate_dfs = {\n",
    "        bound_name: get_barplot_conditions(norm_by_GAfast(\n",
    "            get_avg_rate_df(\n",
    "                get_barplot_conditions(no_outliers),\n",
    "                threshkey=threshkey,\n",
    "                leftthresh=left, rightthresh=right\n",
    "            )\n",
    "        ))[\"average_rate\"]\n",
    "        for bound_name, (left, right) in bounds_set.items()\n",
    "    }\n",
    "    rate_vs_bounds_df = pd.DataFrame.from_dict(rate_dfs)\n",
    "    corr = rate_vs_bounds_df.astype(\"float\").corr(method=\"spearman\")\n",
    "    sns.heatmap(data=corr, cbar=\"viridis\", vmin=0.6)\n",
    "    outpath = f\"../graph_gazing/{threshkey}_corr_heatmap\"\n",
    "    # UNCOMMENT TO SAVE TO FILE\n",
    "    # plt.savefig(f\"{outpath}.svg\")\n",
    "    # plt.savefig(f\"{outpath}.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe37800-b71e-437d-ad7e-4a18a4e6a795",
   "metadata": {},
   "source": [
    "### Calculating from smoothed derivative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f6989-ae78-4a25-8c1b-0f7badc3d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshkey=\"smoothed_derivative\"\n",
    "correlate_bounds(threshkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912ef0b-e3a5-4276-8d5a-ffe6c93da37c",
   "metadata": {},
   "source": [
    "### Calculating from raw derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ba356-2832-443f-ae81-59807be884e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshkey=\"derivative\"\n",
    "correlate_bounds(threshkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275683f-2863-4f61-8b11-e9157a39c3a1",
   "metadata": {},
   "source": [
    "# Analysis within Day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc87eb-7537-4f14-b16a-1c06f7d6440c",
   "metadata": {},
   "source": [
    "## raw traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632eb06-e79e-4f1f-b004-30ff6dc70fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,10)\n",
    "\n",
    "traces = get_traces_conditions(data_df)\n",
    "fig, axes = plt.subplots(3,1, figsize=figsize)\n",
    "fig.tight_layout(h_pad=4)\n",
    "means = traces.groupby([\"condition\", \"date\", \"time\"])[\"smoothed_fluorescence\"].mean().reset_index()\n",
    "\n",
    "for i, ((date, traces_df), (date, means_df), ax) in enumerate(zip(\n",
    "    traces.groupby(\"date\"), means.groupby(\"date\"), axes\n",
    ")):\n",
    "    plot_line_seaborn(\n",
    "        df=traces_df, ykey=\"bkgrd_sub_fluorescence\", \n",
    "        ax=ax, format_xaxis=False, legend=True,\n",
    "    )\n",
    "    plot_traces(\n",
    "        plotted=means_df,\n",
    "        ykey=\"smoothed_fluorescence\", ystyle=\":\",\n",
    "        ax=ax, format_xaxis=False,\n",
    "        plot_bounds=False\n",
    "    )\n",
    "    set_xaxis_time(ax, last_timepoint=\"12hrs\")\n",
    "    ax.set_title(f\"tRNA Batch #{i+1}\")\n",
    "# plt.savefig(\"../figures/all_raw_traces.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059a4c7-0a4e-4319-849a-88e0b93197e3",
   "metadata": {},
   "source": [
    "## derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bcc02a-fec4-4499-9abe-b4681cdfad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,10)\n",
    "\n",
    "traces = get_traces_conditions(data_df)\n",
    "fig, axes = plt.subplots(3,1, figsize=figsize)\n",
    "fig.tight_layout(h_pad=4)\n",
    "\n",
    "for i, ((date, traces_df),  ax) in enumerate(zip(\n",
    "    traces.groupby(\"date\"), axes\n",
    ")):\n",
    "    plot_line_seaborn(\n",
    "        df=traces_df, ykey=\"smoothed_derivative\", \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"tRNA Batch #{i+1}\")\n",
    "# plt.savefig(\"../figures/all_derivatives.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918b9f7-b4ae-4955-9e9f-1d8d359bb7ca",
   "metadata": {},
   "source": [
    "## bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bee7b-c70c-4fc0-820f-d0add7ad3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,10)\n",
    "\n",
    "bars = get_barplot_conditions(rate_w_outliers)\n",
    "fig, axes = plt.subplots(3,1, figsize=figsize)\n",
    "fig.tight_layout(h_pad=4)\n",
    "\n",
    "for i, ((date, bars_df),  ax) in enumerate(zip(bars.groupby(\"date\"), axes)):\n",
    "    ax = sns.stripplot(\n",
    "        data=bars_df, x=barplotval, y=\"condition\",\n",
    "        palette=cmap, size=10, linewidth=2, ax=ax\n",
    "    )\n",
    "    ax = sns.barplot(\n",
    "        data=bars_df, x=barplotval, y=\"condition\",\n",
    "        hue_order=hue_order, palette=cmap, orient=\"h\",\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"tRNA Batch #{i+1}\")\n",
    "    \n",
    "    cond_dict = {cond: df[\"normalized_rate\"] for cond, df in bars_df.groupby(\"condition\")}\n",
    "    stat = ks_2samp(cond_dict[\"GAfast\"], cond_dict[\"GAslow\"], alternative=\"less\")\n",
    "    print(f\"Experiment #{i+1}: ks 2 sample one sided test: p = {stat.pvalue:.2%}\")\n",
    "# plt.savefig(\"../figures/all_bars.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b645c55-13e5-4d07-ba83-7bece8088fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_df[\"normalized_rate\"] = bars_df[\"normalized_rate\"].astype(float)\n",
    "bars_df.groupby(\"condition\")[\"normalized_rate\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635d515-6480-4727-bce0-22b4b3d059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = ks_2samp(cond_dict[\"uniform\"], cond_dict[\"GAslow\"])\n",
    "print(f\"Experiment #{i+1}: ks 2 sample two sided test: p = {stat.pvalue:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01938005-72cf-49a3-8fb0-57399e201f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "just_two_experiments = bars[bars[\"date\"] != \"220728\"]\n",
    "cond_dict = {cond: df[\"normalized_rate\"] for cond, df in just_two_experiments.groupby(\"condition\")}\n",
    "stat = ks_2samp(cond_dict[\"GAfast\"], cond_dict[\"GAslow\"], alternative=\"less\")\n",
    "print(f\"Pooled Experiments 2 and 3: ks 2 sample one sided test: p = {stat.pvalue:.3%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
